{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPYezR41gb7f3/9FSAypQum",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kavya22115/Predictive_Analytics/blob/Creditcard_Fraud_Detection/Creditcardfrauddetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioMrH-T0QXar",
        "outputId": "29b1f9df-6a21-42a0-826b-ac923ec3b05a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    precision_recall_curve, auc\n",
        ")\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv('creditcard.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'creditcard.csv' not found. Please ensure the file is in the correct directory.\")\n",
        "    exit()\n",
        "\n",
        "X = df.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# Check the class distribution of the loaded file\n",
        "print(\"Class distribution of the loaded 'creditcard.csv':\")\n",
        "print(y.value_counts())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])\n",
        "\n",
        "# Correcting train_test_split based on class distribution\n",
        "# If Class 1 has 1 instance, stratify=y will cause an error.\n",
        "# If Class 1 has >1 instance, stratify=y is recommended for imbalanced datasets.\n",
        "if y.value_counts()[1] >= 2 and len(y) >= 2 / 0.2: # Check if enough instances for stratification and test_size\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    print(\"\\nUsed stratify=y in train_test_split.\")\n",
        "else:\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(\"\\nSkipped stratify=y due to insufficient minority class samples for stratified splitting.\")\n",
        "    print(\"Warning: With very few (e.g., 1) minority class samples, building a robust fraud detection model is severely limited.\")\n",
        "    print(\"Consider acquiring a dataset with more fraud instances for meaningful analysis.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Logistic Regression (Baseline) ---\")\n",
        "lr_model = LogisticRegression(solver='liblinear', random_state=42, n_jobs=-1)\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "y_prob_lr = lr_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Confusion Matrix for Logistic Regression:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(\"\\nClassification Report for Logistic Regression:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(f\"ROC AUC Score for Logistic Regression: {roc_auc_score(y_test, y_prob_lr):.4f}\")\n",
        "precision_lr, recall_lr, _ = precision_recall_curve(y_test, y_prob_lr)\n",
        "pr_auc_lr = auc(recall_lr, precision_lr)\n",
        "print(f\"Precision-Recall AUC for Logistic Regression: {pr_auc_lr:.4f}\")\n",
        "\n",
        "print(\"\\n--- Logistic Regression with SMOTE Oversampling ---\")\n",
        "# SMOTE requires at least 2 samples to create synthetic samples.\n",
        "# It also needs more than 1 sample of the minority class to be able to work properly.\n",
        "# Check if SMOTE can be applied. If y_train has only one fraud instance, SMOTE will fail.\n",
        "# Here, we'll only apply SMOTE if there are enough fraud instances in y_train\n",
        "if y_train.value_counts().get(1, 0) > 1: # Check if class 1 has more than 1 instance in training set\n",
        "    pipeline_lr_smote = ImbPipeline([\n",
        "        ('smote', SMOTE(random_state=42, sampling_strategy='auto')),\n",
        "        ('classifier', LogisticRegression(solver='liblinear', random_state=42, n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "    pipeline_lr_smote.fit(X_train, y_train)\n",
        "    y_pred_lr_smote = pipeline_lr_smote.predict(X_test)\n",
        "    y_prob_lr_smote = pipeline_lr_smote.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(\"Confusion Matrix for Logistic Regression with SMOTE:\")\n",
        "    print(confusion_matrix(y_test, y_pred_lr_smote))\n",
        "    print(\"\\nClassification Report for Logistic Regression with SMOTE:\")\n",
        "    print(classification_report(y_test, y_pred_lr_smote))\n",
        "    print(f\"ROC AUC Score for LR with SMOTE: {roc_auc_score(y_test, y_prob_lr_smote):.4f}\")\n",
        "    precision_lr_smote, recall_lr_smote, _ = precision_recall_curve(y_test, y_prob_lr_smote)\n",
        "    pr_auc_lr_smote = auc(recall_lr_smote, precision_lr_smote)\n",
        "    print(f\"Precision-Recall AUC for LR with SMOTE: {pr_auc_lr_smote:.4f}\")\n",
        "else:\n",
        "    print(\"SMOTE Oversampling skipped: Not enough minority class samples in the training set to apply SMOTE effectively.\")\n",
        "\n",
        "print(\"\\n--- Random Forest Classifier ---\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(\"\\nClassification Report for Random Forest Classifier:\")\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(f\"ROC AUC Score for Random Forest: {roc_auc_score(y_test, y_prob_rf):.4f}\")\n",
        "precision_rf, recall_rf, _ = precision_recall_curve(y_test, y_prob_rf)\n",
        "pr_auc_rf = auc(recall_rf, precision_rf)\n",
        "print(f\"Precision-Recall AUC for Random Forest: {pr_auc_rf:.4f}\")\n",
        "\n",
        "print(\"\\n--- Gradient Boosting Classifier ---\")\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "gb_model.fit(X_train, y_train)\n",
        "y_pred_gb = gb_model.predict(X_test)\n",
        "y_prob_gb = gb_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Confusion Matrix for Gradient Boosting Classifier:\")\n",
        "print(confusion_matrix(y_test, y_pred_gb))\n",
        "print(\"\\nClassification Report for Gradient Boosting Classifier:\")\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "print(f\"ROC AUC Score for Gradient Boosting: {roc_auc_score(y_test, y_prob_gb):.4f}\")\n",
        "precision_gb, recall_gb, _ = precision_recall_curve(y_test, y_prob_gb)\n",
        "pr_auc_gb = auc(recall_gb, precision_gb)\n",
        "print(f\"Precision-Recall AUC for Gradient Boosting: {pr_auc_gb:.4f}\")\n",
        "\n",
        "# Plotting PR curves - only if there are enough fraud instances in y_test\n",
        "if y_test.value_counts().get(1, 0) > 0: # Ensure there is at least one fraud case in test set for plotting PR curve\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(recall_lr, precision_lr, label=f'LR (AUC = {pr_auc_lr:.2f})')\n",
        "    # Plot SMOTE curve only if it was run\n",
        "    if y_train.value_counts().get(1, 0) > 1:\n",
        "        plt.plot(recall_lr_smote, precision_lr_smote, label=f'LR+SMOTE (AUC = {pr_auc_lr_smote:.2f})')\n",
        "    plt.plot(recall_rf, precision_rf, label=f'Random Forest (AUC = {pr_auc_rf:.2f})')\n",
        "    plt.plot(recall_gb, precision_gb, label=f'Gradient Boosting (AUC = {pr_auc_gb:.2f})')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('Precision-Recall Curve for Fraud Detection')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"\\nPrecision-Recall Curve not plotted: No fraud instances in the test set to evaluate PR curve.\")\n",
        "\n",
        "print(\"\\n--- Example Prediction for a New Transaction ---\")\n",
        "new_transaction = pd.DataFrame([[0.0, -0.5, 0.5, 1.0, -0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 100.0]],\n",
        "                                  columns=X.columns)\n",
        "new_transaction[['Time', 'Amount']] = scaler.transform(new_transaction[['Time', 'Amount']])\n",
        "predicted_class = gb_model.predict(new_transaction)[0]\n",
        "predicted_prob = gb_model.predict_proba(new_transaction)[0, 1]\n",
        "\n",
        "if predicted_class == 1:\n",
        "    print(f\"Predicted: FRAUD (Probability: {predicted_prob:.4f})\")\n",
        "else:\n",
        "    print(f\"Predicted: NON-FRAUD (Probability: {predicted_prob:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlJWGlpeQatd",
        "outputId": "65ade298-474f-4e59-f17e-25bdc559b226"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution of the loaded 'creditcard.csv':\n",
            "Class\n",
            "0    47\n",
            "1     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Skipped stratify=y due to insufficient minority class samples for stratified splitting.\n",
            "Warning: With very few (e.g., 1) minority class samples, building a robust fraud detection model is severely limited.\n",
            "Consider acquiring a dataset with more fraud instances for meaningful analysis.\n",
            "\n",
            "--- Logistic Regression (Baseline) ---\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[10]]\n",
            "\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "ROC AUC Score for Logistic Regression: nan\n",
            "Precision-Recall AUC for Logistic Regression: 0.5000\n",
            "\n",
            "--- Logistic Regression with SMOTE Oversampling ---\n",
            "SMOTE Oversampling skipped: Not enough minority class samples in the training set to apply SMOTE effectively.\n",
            "\n",
            "--- Random Forest Classifier ---\n",
            "Confusion Matrix for Random Forest Classifier:\n",
            "[[10]]\n",
            "\n",
            "Classification Report for Random Forest Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "ROC AUC Score for Random Forest: nan\n",
            "Precision-Recall AUC for Random Forest: 0.5000\n",
            "\n",
            "--- Gradient Boosting Classifier ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for Gradient Boosting Classifier:\n",
            "[[10]]\n",
            "\n",
            "Classification Report for Gradient Boosting Classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "ROC AUC Score for Gradient Boosting: nan\n",
            "Precision-Recall AUC for Gradient Boosting: 0.5000\n",
            "\n",
            "Precision-Recall Curve not plotted: No fraud instances in the test set to evaluate PR curve.\n",
            "\n",
            "--- Example Prediction for a New Transaction ---\n",
            "Predicted: NON-FRAUD (Probability: 0.0000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:407: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}